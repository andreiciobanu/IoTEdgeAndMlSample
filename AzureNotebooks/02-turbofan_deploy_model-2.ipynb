{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we demonstrate the steps needed to create an IoT Edge deployable module from the regression model created in the [turbofan regression](./turbofan_regression.ipynb) notebook. The steps we will follow are:\n",
        "   1. Reload experiment and model from the Azure Machine Learning service workspace\n",
        "   1. Create a scoring script\n",
        "   1. Create an environment YAML file\n",
        "   1. Create a container image using the model, scoring script and YAML file\n",
        "   1. Deploy the container image as a web service \n",
        "   1. Test the web service to make sure the container works as expected\n",
        "   1. Delete the web service\n",
        "   \n",
        "><font color=gray>Note: this notebook depends on the workspace, experiment and model created in the [turbofan regression](./turbofan_regression.ipynb) notebook.</font>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up notebook\n",
        "\n",
        "Please ensure that you are running this notebook under the Python 3.6 Kernel. The current kernel is show on the top of the notebook at the far right side of the file menu. If you are not running Python 3.6 you can change it in the file menu by clicking **Kernel->Change Kernel->Python 3.6**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611861702944
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure workspace\n",
        "\n",
        "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **aml_config/.azureml/config.json** and loads the details into an object named `ws`, which is used throughout the rest of the code in this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.model import Model\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "\n",
        "ws = Workspace.from_config(path='./aml_config')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611867894029
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws.name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611861708095
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load run, experiment and model\n",
        "\n",
        "Use the model information that we persisted in the [turbofan regression](./turbofan_regression.ipynb) noebook to load our model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "#name project folder and experiment\n",
        "model_data = json.load(open('./aml_config/model_config.json'))\n",
        "\n",
        "run_id = model_data['regressionRunId']\n",
        "experiment_name = model_data['experimentName']\n",
        "model_id = model_data['modelId']\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "automl_run = AutoMLRun(experiment = experiment, run_id = run_id)\n",
        "model = Model(ws, model_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611867903982
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create scoring script\n",
        "\n",
        "The scoring script is the piece of code that runs inside the container and interacts with the model to return a prediction to the caller of web service or Azure IoT Edge module that is running the container. The scoring script is authored knowing the shape of the message that will be sent to the container. In our case, we have chosen to format the message as:\n",
        "\n",
        "```json\n",
        "[{\n",
        "    \"DeviceId\": 81,\n",
        "    \"CycleTime\": 140,\n",
        "    \"OperationalSetting1\": 0.0,\n",
        "    \"OperationalSetting2\": -0.0002,\n",
        "    \"OperationalSetting3\": 100.0,\n",
        "    \"Sensor1\": 518.67,\n",
        "    \"Sensor2\": 642.43,\n",
        "    \"Sensor3\": 1596.02,\n",
        "    \"Sensor4\": 1404.4,\n",
        "    \"Sensor5\": 14.62,\n",
        "    \"Sensor6\": 21.6,\n",
        "    \"Sensor7\": 559.76,\n",
        "    \"Sensor8\": 2388.19,\n",
        "    \"Sensor9\": 9082.16,\n",
        "    \"Sensor10\": 1.31,\n",
        "    \"Sensor11\": 47.6,\n",
        "    \"Sensor12\": 527.82,\n",
        "    \"Sensor13\": 2388.17,\n",
        "    \"Sensor14\": 8155.92,\n",
        "    \"Sensor15\": 8.3214,\n",
        "    \"Sensor16\": 0.03,\n",
        "    \"Sensor17\": 393.0,\n",
        "    \"Sensor18\": 2388.0,\n",
        "    \"Sensor19\": 100.0,\n",
        "    \"Sensor20\": 39.41,\n",
        "    \"Sensor21\": 23.5488\n",
        "}]\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "script_file_name = 'score.py'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611867904570
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial\n",
        "%%writefile $script_file_name\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import azureml.train.automl\n",
        "from sklearn.externals import joblib\n",
        "from azureml.core.model import Model\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    log_for_debug(\"Get model\")\n",
        "    print(Model.get_model_path(model_name = '<<modelname>>'))\n",
        "    model_path = Model.get_model_path(model_name = '<<modelname>>')\n",
        "    # deserialize the model file back into a sklearn model\n",
        "    log_for_debug(\"\")\n",
        "    model = joblib.load(model_path)\n",
        "    \n",
        "def unpack_message(raw_data):\n",
        "    message_data = json.loads(raw_data)\n",
        "    # convert single message to list \n",
        "    if type(message_data) is dict:\n",
        "        message_data = [message_data]\n",
        "    return message_data\n",
        "    \n",
        "def extract_features(message_data):\n",
        "    X_data = []\n",
        "    sensor_names = ['Sensor'+str(i) for i in range(1,22)]\n",
        "    \n",
        "    for message in message_data:\n",
        "        # select sensor data from the message dictionary\n",
        "        feature_dict = {k: message[k] for k in (sensor_names)}\n",
        "        X_data.append(feature_dict)\n",
        "    \n",
        "    X_df = pd.DataFrame(X_data)\n",
        "    return np.array(X_df[sensor_names].values)\n",
        "\n",
        "def append_predict_data(message_data, y_hat):\n",
        "    message_df = pd.DataFrame(message_data)\n",
        "    message_df['PredictedRul'] = y_hat\n",
        "    return message_df.to_dict('records')\n",
        "\n",
        "def log_for_debug(log_message, log_data):\n",
        "    print(\"*****%s:\" % log_message)\n",
        "    print(log_data)\n",
        "    print(\"******\")\n",
        "\n",
        "def run(raw_data):\n",
        "    log_for_debug(\"raw_data\", raw_data)\n",
        "    \n",
        "    message_data = unpack_message(raw_data)\n",
        "    log_for_debug(\"message_data\", message_data)\n",
        "    \n",
        "    X_data = extract_features(message_data)\n",
        "    log_for_debug(\"X_data\", X_data)\n",
        "   \n",
        "    # make prediction\n",
        "    y_hat = model.predict(X_data)\n",
        "    \n",
        "    response_data = append_predict_data(message_data, y_hat)\n",
        "    return response_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_file_name\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import azureml.train.automl\r\n",
        "import joblib\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    log_for_debug(\"Get model\")\r\n",
        "    print(Model.get_model_path(model_name = '<<modelname>>'))\r\n",
        "    model_path = Model.get_model_path(model_name = '<<modelname>>')\r\n",
        "    # deserialize the model file back into a sklearn model\r\n",
        "    log_for_debug(\"\")\r\n",
        "    model = joblib.load(model_path)\r\n",
        "    \r\n",
        "def unpack_message(raw_data):\r\n",
        "    message_data = json.loads(raw_data)\r\n",
        "    # convert single message to list \r\n",
        "    if type(message_data) is dict:\r\n",
        "        message_data = [message_data]\r\n",
        "    return message_data   \r\n",
        "\r\n",
        "def log_for_debug(log_message, log_data):\r\n",
        "    print(\"*****%s:\" % log_message)\r\n",
        "    print(log_data)\r\n",
        "    print(\"******\")\r\n",
        "\r\n",
        "def run(raw_data):\r\n",
        "    log_for_debug(\"raw_data\", raw_data)\r\n",
        "    \r\n",
        "    message_data = unpack_message(raw_data)\r\n",
        "    log_for_debug(\"message_data\", message_data)\r\n",
        "    \r\n",
        "    X_data = extract_features(message_data)\r\n",
        "    log_for_debug(\"X_data\", X_data)\r\n",
        "   \r\n",
        "    # make prediction\r\n",
        "    y_hat = model.predict(X_data)\r\n",
        "    \r\n",
        "    response_data = append_predict_data(message_data, y_hat)\r\n",
        "    return response_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-train-automl"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update the scoring script with the actual model ID"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitute the actual model id in the script file.\n",
        "\n",
        "with open(script_file_name, 'r') as cefr:\n",
        "    content = cefr.read()\n",
        "\n",
        "with open(script_file_name, 'w') as cefw:\n",
        "    cefw.write(content.replace('<<modelname>>', model.name))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611695399139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = automl_run.get_output()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611867934071
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "inference_config = InferenceConfig(environment = best_run.get_environment(), \r\n",
        "                                   entry_script = script_file_name)\r\n",
        "\r\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \r\n",
        "                                               memory_gb = 2, \r\n",
        "                                               tags = {'type': \"automl-forecasting\"},\r\n",
        "                                               description = \"Automl forecasting sample service\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611410072459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aci_service_name = 'automl-forecast'\r\n",
        "print(aci_service_name)\r\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\r\n",
        "aci_service.wait_for_deployment(True)\r\n",
        "print(aci_service.state)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611410262946
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create YAML file for the environment\n",
        "\n",
        "The YAML file provides the information about the dependencies for the model we will deploy. \n",
        "\n",
        "### Get azureml versions\n",
        "\n",
        "First we will use the run to retrieve the version of the azureml packages used to train the model. \n",
        "\n",
        ">Warnings about the version of the SDK not matching with the training version are expected "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = automl_run.get_output()\n",
        "iteration = int(best_run.get_properties()['iteration'])\n",
        "dependencies = automl_run.get_run_sdk_dependencies(iteration = iteration)\n",
        "for p in ['azureml-train-automl-runtime', 'azureml-train-automl-client', 'azureml-automl-runtime', 'azureml-automl-core']:\n",
        "    print('{}\\t{}'.format(p, dependencies[p]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611510253464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write YAML file \n",
        "\n",
        "Write the initial YAML file to disk and update the dependencies for azureml to match with the training versions. This is not strictly needed in this notebook because the model likely has been generated using the current SDK version. However, we include this for completeness for the case when an experiment was trained using a previous SDK version."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "conda_env_file_name = 'myenv.yml'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611867934565
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn','pandas','psutil'], pip_packages=['azureml-defaults','azureml-core'])\n",
        "\n",
        "myenv.save_to_file('.', conda_env_file_name)\n",
        "# Substitute the actual version number in the environment file.\n",
        "with open(conda_env_file_name, 'r') as cefr:\n",
        "    content = cefr.read()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611867936272
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a container image\n",
        "\n",
        "Use the scoring script and the YAML file to create a container image in the workspace. The image will take several minutes to create."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.image import Image, ContainerImage\n",
        "\n",
        "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
        "                                 execution_script = script_file_name,\n",
        "                                 conda_file = conda_env_file_name,\n",
        "                                 tags = {'area': \"digits\", 'type': \"automl_classification\"},\n",
        "                                 description = \"Image for Edge ML samples\")\n",
        "\n",
        "image = Image.create(name = \"edgemlsample\",\n",
        "                     # this is the model object \n",
        "                     models = [model],\n",
        "                     image_config = image_config, \n",
        "                     workspace = ws)\n",
        "\n",
        "image.wait_for_creation(show_output = True)\n",
        "\n",
        "if image.creation_state == 'Failed':\n",
        "    print(\"Image build log at: \" + image.image_build_log_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611868401911
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy image as a web service on Azure Container Instance\n",
        "\n",
        "Deploy the image we just created as web service on Azure Container Instance (ACI). We will use this web service to test that our model/container performs as expected. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "aci_service_name = 'edge-ml-rul-17'\n",
        "\n",
        "# to retrieve the logs:\n",
        "#1) az login\n",
        "#2) az ml service get-logs --verbose --workspace-name turbofanDemo2 --name edge-ml-rul-07\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                               memory_gb = 1, \n",
        "                                               tags = {'area': \"digits\", 'type': \"automl_RUL\"}, \n",
        "                                               description = 'test service for Edge ML RUL')\n",
        "\n",
        "print (\"Deploying service: %s\" % aci_service_name)\n",
        "\n",
        "aci_service = Webservice.deploy_from_image(deployment_config = aci_config,\n",
        "                                           image = image,\n",
        "                                           name = aci_service_name,\n",
        "                                           workspace = ws)\n",
        "\n",
        "aci_service.wait_for_deployment(True)\n",
        "print (\"Service state: %s\" % aci_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deploying service: edge-ml-rul-17\n",
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running.................................................\n",
            "Failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:azureml.core.webservice.webservice:Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: d454f06c-ae6b-489e-9547-5def93441a42\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
            "    },\n",
            "    {\n",
            "      \"code\": \"AciDeploymentFailed\",\n",
            "      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":3,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-01-28T21:35:40.748Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-01-28T21:35:47.921Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:56Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:34:11Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:47Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b0e265c6e684ae4b145176088346f03d2afc32f9a9cff95254f806851f16f66a.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: d454f06c-ae6b-489e-9547-5def93441a42\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":3,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-01-28T21:35:40.748Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-01-28T21:35:47.921Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:56Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:34:11Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:47Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b0e265c6e684ae4b145176088346f03d2afc32f9a9cff95254f806851f16f66a.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: d454f06c-ae6b-489e-9547-5def93441a42\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":3,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2021-01-28T21:35:40.748Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2021-01-28T21:35:47.921Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:32:34Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:32:34Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:42Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:42Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:56Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:35:40Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:34:11Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:35:47Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Killing\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Killing container with id b0e265c6e684ae4b145176088346f03d2afc32f9a9cff95254f806851f16f66a.\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b1566689fed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                            workspace = ws)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Service state: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 915\u001b[0;31m                                                       logs_response, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    916\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    917\u001b[0m                                                                                   operation_state))\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: d454f06c-ae6b-489e-9547-5def93441a42\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":3,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-01-28T21:35:40.748Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-01-28T21:35:47.921Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:32:34Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:33:42Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:33:56Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-01-28T21:34:11Z\\\",\\\"lastTimestamp\\\":\\\"2021-01-28T21:35:47Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b0e265c6e684ae4b145176088346f03d2afc32f9a9cff95254f806851f16f66a.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: d454f06c-ae6b-489e-9547-5def93441a42\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: edge-ml-rul-17. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image 3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":3,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2021-01-28T21:35:40.748Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2021-01-28T21:35:47.921Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:32:34Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:32:34Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:42Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:42Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"3ebd90572dc84c2b85bf2b983aff1dfb.azurecr.io/edgemlsample@sha256:6d02a1380b9b8cab98fab49bd0342b9f3d4dacff329196bef5e6adf565e0903a\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:33:56Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:35:40Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:34:11Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-01-28T21:35:47Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Killing\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Killing container with id b0e265c6e684ae4b145176088346f03d2afc32f9a9cff95254f806851f16f66a.\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(aci_service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611869811823
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load test data\n",
        "\n",
        "To save a couple of steps at this point, we serialized the test data that we loaded in the [turbofan regression](./turbofan_regression.ipynb) notebook. Here we deserialize that data to use it to test the web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.externals import joblib\n",
        "import numpy\n",
        "\n",
        "test_df = pd.read_csv(\"data/WebServiceTest.csv\")\n",
        "\n",
        "test_df.head(5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": {
          "logged": 1611868909839
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict one message at a time\n",
        "\n",
        "Once the container/model is deployed to and Azure IoT Edge device it will receive messages one at a time. Send a few messages in that mode to make sure everything is working."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# reformat data as list of messages\n",
        "X_message = test_df.head(5).to_dict('record')\n",
        "\n",
        "result_list = []\n",
        "for row in X_message:\n",
        "    row_data = json.dumps(row)\n",
        "    row_result = aci_service.run(input_data=row_data)\n",
        "    result_list.append(row_result[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(result_list)\r\n",
        "residuals = result_df['RUL'] - result_df['PredictedRul']\r\n",
        "result_df['Residual'] = residuals\r\n",
        "result_df[['CycleTime','RUL','PredictedRul','Residual']]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict entire set\n",
        "\n",
        "To make sure the model as a whole is working as expected, we send the test set in bulk to the model, save the predictions, and calculate the residual."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "X_messages = test_df.to_dict('record')\n",
        "raw_data = json.dumps(X_messages)\n",
        "\n",
        "result_list = aci_service.run(input_data=raw_data)\n",
        "result_df = pd.DataFrame(result_list)\n",
        "residuals = result_df['RUL'] - result_df['PredictedRul']\n",
        "result_df['Residual'] = residuals\n",
        "\n",
        "y_test = result_df['RUL']\n",
        "y_pred = result_df['PredictedRul']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot actuals vs. predicted\n",
        "\n",
        "To validate the shape of the model, plot the actual RUL against the predicted RUL for each cycle and device."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(8, 4)\n",
        "\n",
        "font_size = 12\n",
        "\n",
        "g = sns.regplot(y='PredictedRul', x='RUL', data=result_df, fit_reg=False, ax=ax)\n",
        "lim_set = g.set(ylim=(0, 500), xlim=(0, 500))\n",
        "plot = g.axes.plot([0, 500], [0, 500], c=\".3\", ls=\"--\");\n",
        "\n",
        "rmse = ax.text(16,450,'RMSE = {0:.2f}'.format(numpy.sqrt(mean_squared_error(y_test, y_pred))), fontsize = font_size)\n",
        "r2 = ax.text(16,425,'R2 Score = {0:.2f}'.format(r2_score(y_test, y_pred)), fontsize = font_size)\n",
        "\n",
        "xlabel = ax.set_xlabel('Actual RUL', size=font_size)\n",
        "ylabel = ax.set_ylabel('Predicted RUL', size=font_size)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete web service\n",
        "\n",
        "Now that we are confident that our container and model are working well, delete the web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import Webservice\n",
        "aci_service = Webservice(ws, 'edge-ml-rul-01')\n",
        "\n",
        "aci_service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}